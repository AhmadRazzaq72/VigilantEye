VIGILANTEYE
============

A Real-Time Traffic Object Detection and Alert System for Foggy Weather

ğŸ“± Platform: Android  
ğŸ§  Model: YOLOv8n (TFLite)  
ğŸ›  Language: Kotlin  
ğŸ¯ Purpose: Enhance road safety by detecting traffic objects in real-time under foggy conditions and alerting drivers.

---

ğŸ“Œ PROJECT OVERVIEW
-------------------
VigilantEye is an offline, on-device Android application built to detect traffic objects in real foggy weather using a lightweight deep learning model (YOLOv8n) optimized with TensorFlow Lite. The app provides real-time alerts using visual cues, audio notifications, and haptic feedback (vibration), enabling drivers to stay safe even in low-visibility environments.

---

ğŸ§ª FEATURES
-----------
âœ… On-device real-time object detection  
âœ… Works in foggy conditions using custom-trained dataset  
âœ… Built with YOLOv8n and deployed via TensorFlow Lite  
âœ… Visual, audio, and vibration alerts on detection  
âœ… Interactive dashboard for statistics and detection reports  
âœ… Lightweight and optimized for performance

---

ğŸ§° TECH STACK
-------------
- Frontend: Kotlin (Android)
- ML Model: YOLOv8n trained on a custom dataset (foggy weather)
- Conversion: PyTorch â†’ ONNX â†’ TFLite
- UI/UX: XML Layouts, ViewBinding
- Others: MPAndroidChart (for charts), CameraX (for camera feed)

---

ğŸ“Š MODEL PERFORMANCE
---------------------
- Model: YOLOv8n (custom-trained on 1600+ foggy images)
- Precision: 0.766
- mAP@50: 0.712
- mAP@50-95: 0.495
- Inference speed: Real-time (~20+ FPS on modern devices)

---

ğŸ“¦ DATASET
-----------
- 1900 real foggy weather images (collected and annotated manually)
- 1548 for training, 181 for validation, 171 for testing
- Annotated using YOLO Labeling Tool

---

ğŸ“£ ALERT SYSTEM
----------------
- ğŸ”Š Sound Alert: Plays audio warning on detection
- ğŸ“³ Vibration: Short pulse when object is nearby
- ğŸ‘ Overlay: Visual box and label over detected object

---

ğŸ“Œ HOW TO RUN
-------------
1. Clone this repo and open it in Android Studio
2. Connect an Android device or use emulator
3. Ensure TFLite model and label file are in `assets/`
4. Build and run the app

---

ğŸ“š LEARNING OUTCOMES
---------------------
This project helped us:
- Gain confidence in machine learning deployment on mobile
- Understand Androidâ€™s CameraX and lifecycle
- Train and convert deep learning models using YOLOv8
- Handle real-time inference with performance optimization
- Develop UI components for statistics and reports
- Improve logic building and debugging skills

---

ğŸ‘¨â€ğŸ’» AUTHOR
------------
Ahmad Razzaq

---
ğŸ“¸ SCREENSHOTS
--------------

![Report Generation](screenshots/report_gen.jpg)
![Report Statistics](screenshots/report_stats.jpg)
![Test - Light Fog](screenshots/test1_light.jpg)
![Test - Moderate Fog](screenshots/test2_moderate.jpg)
